{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c7ab563c",
   "metadata": {},
   "source": [
    "# Introduction to Deep Learning with PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ad90bfb",
   "metadata": {},
   "source": [
    "## 1. Introduction to PyTorch, a Deep Learning library"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a96ee84a",
   "metadata": {},
   "source": [
    "Answer:\n",
    "\n",
    "    Traditional Machine Learning:\n",
    "        Typically relies on hand-crafted feature engineering\n",
    "        Requires relatively less data\n",
    "        Does not require a GPU\n",
    "\n",
    "    Deep Learning:\n",
    "        Can extract patterns from audio signals\n",
    "        Often requires a GPU\n",
    "        Models have a lot of parameters\n",
    "        Can learn features from large, unstructured data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "20099da0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 2, 3, 4])\n"
     ]
    }
   ],
   "source": [
    "# Import PyTorch\n",
    "import torch\n",
    "\n",
    "list_a = [1, 2, 3, 4]\n",
    "\n",
    "# Create a tensor from list_a\n",
    "tensor_a = torch.tensor(list_a)\n",
    "\n",
    "print(tensor_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5d8fc445",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n",
      "torch.int64\n"
     ]
    }
   ],
   "source": [
    "# Display the tensor device\n",
    "print(tensor_a.device)\n",
    "\n",
    "# Display the tensor data type\n",
    "print(tensor_a.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7726be34",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "array_a = np.array([[1, 1, 1], [2, 3, 4], [4, 5, 6]])\n",
    "array_b = np.array([[7, 5, 4], [2, 2, 8], [6, 3, 8]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "12fa3151",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1,  1,  1],\n",
      "        [ 4,  7, 28],\n",
      "        [22, 17, 46]], dtype=torch.int32)\n"
     ]
    }
   ],
   "source": [
    "# Create two tensors from the arrays\n",
    "tensor_a = torch.from_numpy(array_a)\n",
    "tensor_b = torch.from_numpy(array_b)\n",
    "\n",
    "# Subtract tensor_b from tensor_a \n",
    "tensor_c = tensor_a - tensor_b\n",
    "\n",
    "# Multiply each element of tensor_a with each element of tensor_b\n",
    "tensor_d = tensor_a * tensor_b\n",
    "\n",
    "# Add tensor_c with tensor_d\n",
    "tensor_e = tensor_c + tensor_d\n",
    "print(tensor_e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "95f3dd7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.6033]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "input_tensor = torch.Tensor([[2, 3, 6, 7, 9, 3, 2, 1]])\n",
    "\n",
    "# Implement a small neural network with exactly two linear layers\n",
    "model = nn.Sequential(nn.Linear(8, 1),\n",
    "                      nn.Linear(1, 1)\n",
    "                     )\n",
    "\n",
    "output = model(input_tensor)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dd9a200",
   "metadata": {},
   "source": [
    "Answer:\n",
    "    \n",
    "    nn.Sequential(\n",
    "        nn.Linear(12, 20),\n",
    "        nn.Linear(20, 14),\n",
    "        nn.Linear(14, 3),\n",
    "        nn.Linear(3, 2)\n",
    "       )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c26f40c",
   "metadata": {},
   "source": [
    "Answer:\n",
    "    \n",
    "    A neural network with a single linear layer followed by a sigmoid activation is similar to a logistic regression model.\n",
    "    The input dimension of a linear layer must be equal to the output dimension of the previous layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c9245def",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.6900]])\n"
     ]
    }
   ],
   "source": [
    "score = torch.tensor([[0.8]])\n",
    "\n",
    "# Create a sigmoid function and apply it on the score tensor\n",
    "sigmoid = nn.Sigmoid()\n",
    "probability = sigmoid(score)\n",
    "print(probability)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e0053892",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.2828e-01, 1.1698e-04, 5.7492e-01, 3.4961e-02, 1.5669e-01, 1.0503e-01]])\n"
     ]
    }
   ],
   "source": [
    "scores = torch.tensor([[1.0, -6.0, 2.5, -0.3, 1.2, 0.8]])\n",
    "\n",
    "# Create a softmax function and apply it on the score tensor\n",
    "softmax = nn.Softmax(dim=-1)\n",
    "probabilities = softmax(scores)\n",
    "print(probabilities)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96122664",
   "metadata": {},
   "source": [
    "## 2. Training Our First Neural Network with PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3c47e6cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.1197, 0.3246]], grad_fn=<SigmoidBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "input_tensor = torch.Tensor([[3, 4, 6, 2, 3, 6, 8, 9]])\n",
    "\n",
    "# Implement a small neural network for binary classification\n",
    "model = nn.Sequential(\n",
    "  nn.Linear(8, 1),\n",
    "  nn.Linear(1, 2),\n",
    "  nn.Sigmoid()\n",
    ")\n",
    "\n",
    "output = model(input_tensor)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3f5bb78",
   "metadata": {},
   "source": [
    "Answer: It can take any float value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e25ea8d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0723]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "input_tensor = torch.Tensor([[3, 4, 6, 7, 10, 12, 2, 3, 6, 8, 9]])\n",
    "\n",
    "# Implement a neural network with exactly four linear layers\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(11, 7),\n",
    "    nn.Linear(7, 3),\n",
    "    nn.Linear(3, 6),\n",
    "    nn.Linear(6, 1)\n",
    ")\n",
    "\n",
    "output = model(input_tensor)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "11e3c463",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.1988, 0.4097, 0.2425, 0.1490]], grad_fn=<SoftmaxBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "input_tensor = torch.Tensor([[3, 4, 6, 7, 10, 12, 2, 3, 6, 8, 9]])\n",
    "\n",
    "# Update network below to perform a multi-class classification with four labels\n",
    "model = nn.Sequential(\n",
    "  nn.Linear(11, 20),\n",
    "  nn.Linear(20, 12),\n",
    "  nn.Linear(12, 6),\n",
    "  nn.Linear(6, 4),\n",
    "  nn.Softmax(dim=-1)\n",
    ")\n",
    "\n",
    "output = model(input_tensor)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6351e23d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "y = 1\n",
    "num_classes = 3\n",
    "\n",
    "# Create the one-hot encoded vector using NumPy\n",
    "one_hot_numpy = np.array([0, 1, 0])\n",
    "\n",
    "# Create the one-hot encoded vector using PyTorch\n",
    "one_hot_pytorch = F.one_hot(torch.tensor(y), num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a3bf00f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "y = [2]\n",
    "scores = torch.tensor([[0.1, 6.0, -2.0, 3.2]])\n",
    "\n",
    "# Create a one-hot encoded vector of the label y\n",
    "one_hot_label = F.one_hot(torch.tensor(y), num_classes=scores.size(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "15ad85c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(8.0619, dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "# Create the cross entropy loss function\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Calculate the cross entropy loss\n",
    "loss = criterion(scores.double(), one_hot_label.double())\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94022330",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = torch.tensor([[0.5949, 1.7531]], requires_grad=True)\n",
    "target = torch.tensor([1], dtype=torch.long)\n",
    "weight = torch.tensor([[5.0948e-01, 3.5392e-01, 1.5075e+00, -1.1572e+00, 1.9524e+00, -1.0543e-03, 2.5741e-01, 8.4456e-01, \n",
    "                        2.5092e-01], [-2.9786e-01, -1.8137e-01, 1.7039e+00, -3.0650e-01, 1.8729e-01, 9.8279e-01, 3.1741e-01, \n",
    "                                      -1.1760e+00, 8.2644e-01]], requires_grad=True)\n",
    "bias = torch.tensor([-2.0824, 0.8604], requires_grad=True)\n",
    "\n",
    "# Create the cross entropy loss function\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Calculate the loss\n",
    "loss = criterion(preds, target)\n",
    "\n",
    "# Compute the gradients of the loss\n",
    "loss.backward()\n",
    "\n",
    "# Display gradients of the weight and bias tensors in order\n",
    "print(weight.grad)\n",
    "print(bias.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "09d27166",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(nn.Linear(16, 8),\n",
    "                      nn.Sigmoid(),\n",
    "                      nn.Linear(8, 2))\n",
    "\n",
    "# Access the weight of the first linear layer\n",
    "weight_0 = model[0].weight\n",
    "\n",
    "# Access the bias of the second linear layer\n",
    "bias_1 = model[2].bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fab549de",
   "metadata": {},
   "outputs": [],
   "source": [
    "weight0 = model[0].weight\n",
    "weight1 = model[1].weight\n",
    "weight2 = model[2].weight\n",
    "\n",
    "# Access the gradients of the weight of each linear layer\n",
    "grads0 = weight0.grad\n",
    "grads1 = weight1.grad\n",
    "grads2 = weight2.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cee20c4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "weight0 = model[0].weight\n",
    "weight1 = model[1].weight\n",
    "weight2 = model[2].weight\n",
    "\n",
    "# Access the gradients of the weight of each linear layer\n",
    "grads0 = model[0].weight.grad\n",
    "grads1 = model[1].weight.grad\n",
    "grads2 = model[2].weight.grad\n",
    "\n",
    "# Update the weights using the learning rate and the gradients\n",
    "weight0 = weight0 - lr * grads0\n",
    "weight1 = weight1 - lr * grads1\n",
    "weight2 = weight2 - lr * grads2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "404fab23",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "# Create the optimizer\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "03466173",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = torch.tensor([[-0.3243, -0.2986]], requires_grad=True)\n",
    "target = torch.tensor([[1., 0.]])\n",
    "\n",
    "# Create the optimizer\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001)\n",
    "\n",
    "loss = criterion(pred, target)\n",
    "loss.backward()\n",
    "\n",
    "# Update the model's parameters using the optimizer\n",
    "optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f077a9ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(81.)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Erturk Memmedli\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='mean' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    }
   ],
   "source": [
    "y_hat = np.array(10)\n",
    "y = np.array(1)\n",
    "\n",
    "# Calculate the MSELoss using NumPy\n",
    "mse_numpy = np.mean((y_hat - y)**2)\n",
    "\n",
    "# Create the MSELoss function\n",
    "criterion = nn.MSELoss(y_hat, y)\n",
    "\n",
    "# Calculate the MSELoss using the created loss function\n",
    "mse_pytorch = criterion(torch.tensor(y_hat, dtype=torch.float32), torch.tensor(y, dtype=torch.float32))\n",
    "print(mse_pytorch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa433cec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop over the number of epochs and the dataloader\n",
    "for i in range(num_epochs):\n",
    "    for data in dataloader:\n",
    "        # Set the gradients to zero\n",
    "        optimizer.zero_grad()\n",
    "        # Run a forward pass\n",
    "        feature, target = data\n",
    "        prediction = model(feature)    \n",
    "        # Calculate the loss\n",
    "        loss = criterion(prediction, target)    \n",
    "        # Compute the gradients\n",
    "        loss.backward()\n",
    "        # Update the model's parameters\n",
    "        optimizer.step()\n",
    "show_results(model, dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c138077f",
   "metadata": {},
   "source": [
    "## 3. Neural Network Architecture and Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "17b33afd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.)\n"
     ]
    }
   ],
   "source": [
    "# Create a ReLU function with PyTorch\n",
    "relu_pytorch = nn.ReLU()\n",
    "\n",
    "# Apply your ReLU function on x, and calculate gradients\n",
    "x = torch.tensor(-1.0, requires_grad=True)\n",
    "y = relu_pytorch(x)\n",
    "y.backward()\n",
    "\n",
    "# Print the gradient of the ReLU function for x\n",
    "gradient = x.grad\n",
    "print(gradient)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "2a424fda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-0.1000)\n"
     ]
    }
   ],
   "source": [
    "# Create a leaky relu function in PyTorch\n",
    "leaky_relu_pytorch = nn.LeakyReLU(negative_slope=0.05)\n",
    "\n",
    "x = torch.tensor(-2.0)\n",
    "# Call the above function on the tensor x\n",
    "output = leaky_relu_pytorch(x)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "11bfc9da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-0.1500)\n"
     ]
    }
   ],
   "source": [
    "# Create a leaky relu function in PyTorch\n",
    "leaky_relu_pytorch = nn.LeakyReLU(negative_slope=0.05)\n",
    "\n",
    "x = torch.tensor(-3.0)\n",
    "# Call the above function on the tensor x\n",
    "output = leaky_relu_pytorch(x)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "567c6d52",
   "metadata": {},
   "source": [
    "Answer: -0.15"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5fc0a26",
   "metadata": {},
   "source": [
    "Answer:\n",
    "    \n",
    "    The ReLU activation function only outputs zero for negative inputs.\n",
    "    ReLU(x) = 3 for x = 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "bd9d030b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "81\n"
     ]
    }
   ],
   "source": [
    "model = nn.Sequential(nn.Linear(16, 4),\n",
    "                      nn.Linear(4, 2),\n",
    "                      nn.Linear(2, 1))\n",
    "\n",
    "total = 0\n",
    "\n",
    "# Calculate the number of parameters in the model\n",
    "for parameter in model.parameters():\n",
    "    total += parameter.numel()\n",
    "    \n",
    "print(total)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e320fab1",
   "metadata": {},
   "source": [
    "Answer: 81"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "907d811a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_capacity(model):\n",
    "    total = 0\n",
    "    for p in model.parameters():\n",
    "        total += p.numel()\n",
    "    return total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "b7fa3820",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92\n"
     ]
    }
   ],
   "source": [
    "n_features = 8\n",
    "n_classes = 2\n",
    "\n",
    "input_tensor = torch.Tensor([[3, 4, 6, 2, 3, 6, 8, 9]])\n",
    "\n",
    "# Create a neural network with less than 120 parameters\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(n_features, 6),\n",
    "    nn.Linear(6, 4),\n",
    "    nn.Linear(4, n_classes)\n",
    ")\n",
    "output = model(input_tensor)\n",
    "\n",
    "print(calculate_capacity(model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "82d65dad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "151\n"
     ]
    }
   ],
   "source": [
    "n_features = 8\n",
    "n_classes = 2\n",
    "\n",
    "input_tensor = torch.Tensor([[3, 4, 6, 2, 3, 6, 8, 9]])\n",
    "\n",
    "# Create a neural network with more than 120 parameters\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(n_features, 8),\n",
    "    nn.Linear(8, 5),\n",
    "    nn.Linear(5, 4),\n",
    "    nn.Linear(4, n_classes)\n",
    ")\n",
    "\n",
    "output = model(input_tensor)\n",
    "\n",
    "print(calculate_capacity(model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "679e2bc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try a first learning rate value\n",
    "lr0 = 0.001\n",
    "optimize_and_plot(lr=lr0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "834ff8b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try a second learning rate value\n",
    "lr1 = 0.1\n",
    "optimize_and_plot(lr=lr1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d32d7ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try a third learning rate value\n",
    "lr2 = 0.085\n",
    "optimize_and_plot(lr=lr2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0841b02d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try a first value for momentum\n",
    "mom0 = 0.85\n",
    "optimize_and_plot(momentum=mom0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f284fd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try a second value for momentum\n",
    "mom1 = 0.95\n",
    "optimize_and_plot(momentum=mom1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e4f93ed",
   "metadata": {},
   "source": [
    "Answer:\n",
    "    \n",
    "    Find a model trained on a similar task\n",
    "    Load pre-trained weights\n",
    "    Freeze (or not) some of the layers in the model\n",
    "    Train with a smaller learning rate\n",
    "    Look at the loss values and see if the learning rate needs to be adjusted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "174c354b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, param in model.named_parameters():    \n",
    "  \n",
    "    # Check if the parameters belong to the first layer\n",
    "    if name == '0.weight' or name == '0.bias':\n",
    "      \n",
    "        # Freeze the parameters\n",
    "        param.requires_grad = False\n",
    "  \n",
    "    # Check if the parameters belong to the second layer\n",
    "    if name == '1.weight' or name == '1.bias':\n",
    "      \n",
    "        # Freeze the parameters\n",
    "        param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "8fb0bbc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer0 = nn.Linear(16, 32)\n",
    "layer1 = nn.Linear(32, 64)\n",
    "\n",
    "# Use uniform initialization for layer0 and layer1 weights\n",
    "nn.init.uniform_(layer0.weight, a=0, b=1)\n",
    "nn.init.uniform_(layer1.weight, a=0, b=1)\n",
    "\n",
    "model = nn.Sequential(layer0, layer1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c281fbce",
   "metadata": {},
   "source": [
    "## 4. Evaluating and Improving Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "36d7dcc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([0.3216, 0.6335, 0.6974, 0.4446, 0.8613, 0.2529, 0.8226, 0.1453],\n",
      "       dtype=torch.float64), tensor([0.4125], dtype=torch.float64))\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset\n",
    "\n",
    "np_features = np.array(np.random.rand(12, 8))\n",
    "np_target = np.array(np.random.rand(12, 1))\n",
    "\n",
    "# Convert arrays to PyTorch tensors\n",
    "torch_features = torch.tensor(np_features)\n",
    "torch_target = torch.tensor(np_target)\n",
    "\n",
    "# Create a TensorDataset from two tensors\n",
    "dataset = TensorDataset(torch_features, torch_target)\n",
    "\n",
    "# Return the last element of this dataset\n",
    "print(dataset[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "c69f6332",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ph</th>\n",
       "      <th>Hardness</th>\n",
       "      <th>Solids</th>\n",
       "      <th>Chloramines</th>\n",
       "      <th>Sulfate</th>\n",
       "      <th>Conductivity</th>\n",
       "      <th>Organic_carbon</th>\n",
       "      <th>Trihalomethanes</th>\n",
       "      <th>Turbidity</th>\n",
       "      <th>Potability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.587349</td>\n",
       "      <td>0.577747</td>\n",
       "      <td>0.386298</td>\n",
       "      <td>0.568199</td>\n",
       "      <td>0.647347</td>\n",
       "      <td>0.292985</td>\n",
       "      <td>0.654522</td>\n",
       "      <td>0.795029</td>\n",
       "      <td>0.630115</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.643654</td>\n",
       "      <td>0.441300</td>\n",
       "      <td>0.314381</td>\n",
       "      <td>0.439304</td>\n",
       "      <td>0.514545</td>\n",
       "      <td>0.356685</td>\n",
       "      <td>0.377248</td>\n",
       "      <td>0.202914</td>\n",
       "      <td>0.520358</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.388934</td>\n",
       "      <td>0.470876</td>\n",
       "      <td>0.506122</td>\n",
       "      <td>0.524364</td>\n",
       "      <td>0.561537</td>\n",
       "      <td>0.142913</td>\n",
       "      <td>0.249922</td>\n",
       "      <td>0.401487</td>\n",
       "      <td>0.219973</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.725820</td>\n",
       "      <td>0.715942</td>\n",
       "      <td>0.506141</td>\n",
       "      <td>0.521683</td>\n",
       "      <td>0.751819</td>\n",
       "      <td>0.148683</td>\n",
       "      <td>0.467200</td>\n",
       "      <td>0.658678</td>\n",
       "      <td>0.242428</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.610517</td>\n",
       "      <td>0.532588</td>\n",
       "      <td>0.237701</td>\n",
       "      <td>0.270288</td>\n",
       "      <td>0.495155</td>\n",
       "      <td>0.494792</td>\n",
       "      <td>0.409721</td>\n",
       "      <td>0.469762</td>\n",
       "      <td>0.585049</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         ph  Hardness    Solids  Chloramines   Sulfate  Conductivity  \\\n",
       "0  0.587349  0.577747  0.386298     0.568199  0.647347      0.292985   \n",
       "1  0.643654  0.441300  0.314381     0.439304  0.514545      0.356685   \n",
       "2  0.388934  0.470876  0.506122     0.524364  0.561537      0.142913   \n",
       "3  0.725820  0.715942  0.506141     0.521683  0.751819      0.148683   \n",
       "4  0.610517  0.532588  0.237701     0.270288  0.495155      0.494792   \n",
       "\n",
       "   Organic_carbon  Trihalomethanes  Turbidity  Potability  \n",
       "0        0.654522         0.795029   0.630115           0  \n",
       "1        0.377248         0.202914   0.520358           0  \n",
       "2        0.249922         0.401487   0.219973           0  \n",
       "3        0.467200         0.658678   0.242428           0  \n",
       "4        0.409721         0.469762   0.585049           0  "
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "dataframe = pd.read_csv('water_potability.csv')\n",
    "dataframe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "eca6840c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.3362],\n",
      "        [-0.2760],\n",
      "        [-0.2499],\n",
      "        ...,\n",
      "        [-0.2864],\n",
      "        [-0.3019],\n",
      "        [-0.3390]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "# Load the different columns into two PyTorch tensors\n",
    "features = torch.tensor(np.array(dataframe[['ph', 'Sulfate', 'Conductivity', 'Organic_carbon']])).float()\n",
    "target = torch.tensor(np.array(dataframe['Potability'])).float()\n",
    "\n",
    "# Create a dataset from the two generated tensors\n",
    "dataset = TensorDataset(features, target)\n",
    "\n",
    "# Create a dataloader using the above dataset\n",
    "dataloader = DataLoader(dataset, shuffle=True, batch_size=2)\n",
    "x, y = next(iter(dataloader))\n",
    "\n",
    "# Create a model using the nn.Sequential API\n",
    "model = nn.Sequential(\n",
    "  nn.Linear(len(features[0]), 8),\n",
    "  nn.Linear(8, 1)\n",
    ")\n",
    "output = model(features)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a145292f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the model to evaluation mode\n",
    "model.eval()\n",
    "validation_loss = 0.0\n",
    "\n",
    "with torch.no_grad():\n",
    "  \n",
    "    for data in validationloader:\n",
    "    \n",
    "        outputs = model(data[0])\n",
    "        loss = criterion(outputs, data[1])\n",
    "      \n",
    "        # Sum the current loss to the validation_loss variable\n",
    "        validation_loss += loss.item()\n",
    "        \n",
    "# Calculate the mean loss value\n",
    "validation_loss_epoch = validation_loss / len(validationloader)\n",
    "print(validation_loss_epoch)\n",
    "\n",
    "# Set the model back to training mode\n",
    "model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6303fd6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchmetrics\n",
    "\n",
    "# Create accuracy metric using torch metrics\n",
    "metric = torchmetrics.Accuracy(task=\"multiclass\", num_classes=3)\n",
    "for data in dataloader:\n",
    "    features, labels = data\n",
    "    outputs = model(features)\n",
    "    \n",
    "    # Calculate accuracy over the batch\n",
    "    acc = metric(outputs.softmax(dim=-1), labels.argmax(dim=-1))\n",
    "    \n",
    "# Calculate accuracy over the whole epoch\n",
    "acc = metric.compute()\n",
    "\n",
    "# Reset the metric for the next epoch \n",
    "metric.reset()\n",
    "plot_errors(model, dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63b170e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a small neural network\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(3072, 16),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout()\n",
    ")\n",
    "model(input_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fd260f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the same model, set the dropout probability to 0.8\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(3072, 16),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(p=0.8)\n",
    ")\n",
    "model(input_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02022afb",
   "metadata": {},
   "source": [
    "Answer:\n",
    "    \n",
    "    Overfitting happens when the model is performing worse on the validation set than on the training set.\n",
    "    Data augmentation can reduce overfitting by artificially increasing the size of the training set.\n",
    "    A dropout layer with a probability strictly superior to zero will reduce overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "319fa9bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "values = []\n",
    "for idx in range(10):\n",
    "    # Randomly sample a learning rate factor between 0.01 and 0.0001\n",
    "    factor = np.random.uniform(2, 4) \n",
    "\n",
    "    lr = 10 ** -factor\n",
    "    \n",
    "    # Randomly select a momentum between 0.85 and 0.99\n",
    "    momentum = np.random.uniform(0.85, 0.99)\n",
    "    \n",
    "    values.append((lr, momentum))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
